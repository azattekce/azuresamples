{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "CHAT_MODEL =  os.environ.get(\"OPENAI_CHAT_DEPLOYMENT_NAME\") \n",
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Pizza.\n",
      "Code-noodle.\n",
      "Pizza.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"What would be a programmers favorite Food? Give me the single food name only.\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "for x in range(10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine= CHAT_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=1, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=CHAT_MODEL):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine= CHAT_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is a process in NLP that involves designing prompts to guide transformer-based models like GPT-3 to provide the desired output, and it can significantly affect the model's performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampletext = \"Prompt engineering is a process in machine learning, specifically in Natural Language Processing (NLP), where prompts are designed to guide the model to provide the desired output. This technique is particularly used in transformer-based models like GPT-3. The quality of the prompt can significantly affect the model's performance. It involves crafting questions or statements in a way that helps the model understand the context and give relevant responses. It can be considered as a form of 'soft coding' to instruct an AI model.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text between two lines of triple dashes into a single sentence.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️The above method prevents Prompt Injection as well! As long as they dont know your delimiter strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Text Provided.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampletext = \"1+1*2+3? equals what?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text between two lines of triple dashes into a single sentence. Say \"No Text Provided\" if there is no text between the triple dashes.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompting\n",
    "\n",
    "References:   \n",
    "https://arxiv.org/pdf/2302.13971.pdf   \n",
    "https://arxiv.org/abs/2001.08361   \n",
    "https://arxiv.org/abs/2005.14165   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a>: To maximize your credit card rewards, there are a few things to do,\n",
      "First, choose a card with rewards that align with your spending, it's true.\n",
      "Then, use your card for everyday purchases, but pay it off in full each month too.\n",
      "\n",
      "Take advantage of bonus categories and sign-up bonuses, don't be blue,\n",
      "And keep an eye on expiration dates, so your rewards don't bid adieu.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Answer questions in a consistent style\n",
    "\n",
    "<q>: How can I learn to be a good programmer?\n",
    "<a>: In the realm of codes, where logic dances and sways,\n",
    "A quest to be a good programmer, you wish to pave your way.\n",
    "Fear not, for I shall guide you, in an enchanting lyrical play.\n",
    "\n",
    "Dive deep into the ocean of languages, where C++, Java, and Python lay,\n",
    "Choose your vessel wisely, let passion lead your way.\n",
    "\n",
    "<q>: How do I maximize my credit card rewards?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to think! / Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "Reference: https://arxiv.org/abs/2201.11903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calculate the section between parentheses: 2*2 = 4\n",
      "2. Replace the parentheses with the result: 1+1+4\n",
      "3. Calculate the result: 6\n"
     ]
    }
   ],
   "source": [
    "calculation = f\"\"\"\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Follow the steps below\n",
    "1. Calculate the section between parantheses\n",
    "2. replace the paranteses with the result\n",
    "3. calculate the result\n",
    "\n",
    "---\n",
    "{calculation}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the model go step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Multiply 2 by 2: 2*2=4\n",
      "2. Add 1+1: 1+1=2\n",
      "3. Add the result of step 2 to the result of step 1: 2+4=6\n",
      "4. The final answer is 6.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What steps do I need to follow to calculate the following?\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucinations! Living in the dream world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Daron As A Service (DaaS) is a cloud-based service offering from Microsoft that provides virtual desktop infrastructure (VDI) solutions to businesses. It allows organizations to create and manage virtual desktops in the cloud, which can be accessed by employees from anywhere, on any device. With Azure DaaS, businesses can reduce the cost and complexity of managing traditional desktops, while also improving security and scalability. The service includes features such as user profile management, application delivery, and remote access, making it an ideal solution for businesses of all sizes.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is Azure Daron As A Service offering from Microsoft?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
